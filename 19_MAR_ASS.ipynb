{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCtTb8/jmq9epsGOYg9L8N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishqacodes/DATA-SCIENCE-MASTERS/blob/main/19_MAR_ASS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
        "\n",
        "Min-Max scaling, also known as normalization, is a data preprocessing technique used to transform numerical features within a specific range. It rescales the data, bringing it to a common scale, typically between 0 and 1.\n",
        "\n",
        "The purpose of Min-Max scaling is to eliminate the influence of the original values' magnitude, preventing certain features from dominating the learning algorithms simply due to their larger values.\n",
        "\n",
        "\n",
        "**X_scaled = (X - X_min) / (X_max - X_min)**\n",
        "\n",
        "EXAMPLE :-"
      ],
      "metadata": {
        "id": "4kC2XaCvK7d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "min_max=MinMaxScaler()"
      ],
      "metadata": {
        "id": "lgMInSBVtOE9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "df=sns.load_dataset('taxis')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "0N7UiHn-tsrq",
        "outputId": "4c19b481-a2e0-4ea9-f0ab-9fc45c0530b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               pickup             dropoff  passengers  distance  fare   tip  \\\n",
              "0 2019-03-23 20:21:09 2019-03-23 20:27:24           1      1.60   7.0  2.15   \n",
              "1 2019-03-04 16:11:55 2019-03-04 16:19:00           1      0.79   5.0  0.00   \n",
              "2 2019-03-27 17:53:01 2019-03-27 18:00:25           1      1.37   7.5  2.36   \n",
              "3 2019-03-10 01:23:59 2019-03-10 01:49:51           1      7.70  27.0  6.15   \n",
              "4 2019-03-30 13:27:42 2019-03-30 13:37:14           3      2.16   9.0  1.10   \n",
              "\n",
              "   tolls  total   color      payment            pickup_zone  \\\n",
              "0    0.0  12.95  yellow  credit card        Lenox Hill West   \n",
              "1    0.0   9.30  yellow         cash  Upper West Side South   \n",
              "2    0.0  14.16  yellow  credit card          Alphabet City   \n",
              "3    0.0  36.95  yellow  credit card              Hudson Sq   \n",
              "4    0.0  13.40  yellow  credit card           Midtown East   \n",
              "\n",
              "            dropoff_zone pickup_borough dropoff_borough  \n",
              "0    UN/Turtle Bay South      Manhattan       Manhattan  \n",
              "1  Upper West Side South      Manhattan       Manhattan  \n",
              "2           West Village      Manhattan       Manhattan  \n",
              "3         Yorkville West      Manhattan       Manhattan  \n",
              "4         Yorkville West      Manhattan       Manhattan  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45dccf8c-357e-43b3-bed5-59d8887e375a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup</th>\n",
              "      <th>dropoff</th>\n",
              "      <th>passengers</th>\n",
              "      <th>distance</th>\n",
              "      <th>fare</th>\n",
              "      <th>tip</th>\n",
              "      <th>tolls</th>\n",
              "      <th>total</th>\n",
              "      <th>color</th>\n",
              "      <th>payment</th>\n",
              "      <th>pickup_zone</th>\n",
              "      <th>dropoff_zone</th>\n",
              "      <th>pickup_borough</th>\n",
              "      <th>dropoff_borough</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-03-23 20:21:09</td>\n",
              "      <td>2019-03-23 20:27:24</td>\n",
              "      <td>1</td>\n",
              "      <td>1.60</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.95</td>\n",
              "      <td>yellow</td>\n",
              "      <td>credit card</td>\n",
              "      <td>Lenox Hill West</td>\n",
              "      <td>UN/Turtle Bay South</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-03-04 16:11:55</td>\n",
              "      <td>2019-03-04 16:19:00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.79</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.30</td>\n",
              "      <td>yellow</td>\n",
              "      <td>cash</td>\n",
              "      <td>Upper West Side South</td>\n",
              "      <td>Upper West Side South</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-03-27 17:53:01</td>\n",
              "      <td>2019-03-27 18:00:25</td>\n",
              "      <td>1</td>\n",
              "      <td>1.37</td>\n",
              "      <td>7.5</td>\n",
              "      <td>2.36</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.16</td>\n",
              "      <td>yellow</td>\n",
              "      <td>credit card</td>\n",
              "      <td>Alphabet City</td>\n",
              "      <td>West Village</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-03-10 01:23:59</td>\n",
              "      <td>2019-03-10 01:49:51</td>\n",
              "      <td>1</td>\n",
              "      <td>7.70</td>\n",
              "      <td>27.0</td>\n",
              "      <td>6.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.95</td>\n",
              "      <td>yellow</td>\n",
              "      <td>credit card</td>\n",
              "      <td>Hudson Sq</td>\n",
              "      <td>Yorkville West</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-03-30 13:27:42</td>\n",
              "      <td>2019-03-30 13:37:14</td>\n",
              "      <td>3</td>\n",
              "      <td>2.16</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.40</td>\n",
              "      <td>yellow</td>\n",
              "      <td>credit card</td>\n",
              "      <td>Midtown East</td>\n",
              "      <td>Yorkville West</td>\n",
              "      <td>Manhattan</td>\n",
              "      <td>Manhattan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45dccf8c-357e-43b3-bed5-59d8887e375a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45dccf8c-357e-43b3-bed5-59d8887e375a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45dccf8c-357e-43b3-bed5-59d8887e375a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_max.fit_transform(df[['distance','fare','tip']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97H6YNTTtRyJ",
        "outputId": "4e5aef3c-b5a8-4963-9464-a104265076f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.04359673, 0.04026846, 0.06475904],\n",
              "       [0.02152589, 0.02684564, 0.        ],\n",
              "       [0.0373297 , 0.04362416, 0.07108434],\n",
              "       ...,\n",
              "       [0.11280654, 0.10067114, 0.        ],\n",
              "       [0.03051771, 0.03355705, 0.        ],\n",
              "       [0.10490463, 0.09395973, 0.10120482]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
        "\n",
        "The Unit Vector technique, also known as normalization, is another data preprocessing method used for feature scaling. Unlike Min-Max scaling, which scales the data to a specific range, Unit Vector scaling aims to normalize the vector representation of each data point.\n",
        "\n",
        "The Unit Vector technique scales each data point such that its Euclidean norm (or length) becomes 1. It ensures that the vector retains its direction while adjusting its magnitude to a unit length. This scaling technique is particularly useful when the direction of the data points is important, such as in cases where similarity or distance calculations are involved.\n",
        "\n",
        "**X_scaled = X / ||X||**\n",
        "\n"
      ],
      "metadata": {
        "id": "vaviwet2uA6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "id": "El2KvxGytzbG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(normalize(df[['distance','fare','tip']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "I-rTq4tYuKUb",
        "outputId": "791775be-8c55-416e-ecdd-28f7a4d7d379"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2\n",
              "0     0.213461  0.933894  0.286839\n",
              "1     0.156064  0.987747  0.000000\n",
              "2     0.171657  0.939731  0.295702\n",
              "3     0.267899  0.939386  0.213971\n",
              "4     0.231742  0.965592  0.118017\n",
              "...        ...       ...       ...\n",
              "6428  0.160133  0.960800  0.226322\n",
              "6429  0.307453  0.951563  0.000000\n",
              "6430  0.250500  0.968117  0.000000\n",
              "6431  0.183497  0.983020  0.000000\n",
              "6432  0.242956  0.946580  0.212034\n",
              "\n",
              "[6433 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5c8ce96-5018-415a-b8aa-cedfd1e07d14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.213461</td>\n",
              "      <td>0.933894</td>\n",
              "      <td>0.286839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.156064</td>\n",
              "      <td>0.987747</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.171657</td>\n",
              "      <td>0.939731</td>\n",
              "      <td>0.295702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.267899</td>\n",
              "      <td>0.939386</td>\n",
              "      <td>0.213971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.231742</td>\n",
              "      <td>0.965592</td>\n",
              "      <td>0.118017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6428</th>\n",
              "      <td>0.160133</td>\n",
              "      <td>0.960800</td>\n",
              "      <td>0.226322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6429</th>\n",
              "      <td>0.307453</td>\n",
              "      <td>0.951563</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6430</th>\n",
              "      <td>0.250500</td>\n",
              "      <td>0.968117</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6431</th>\n",
              "      <td>0.183497</td>\n",
              "      <td>0.983020</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6432</th>\n",
              "      <td>0.242956</td>\n",
              "      <td>0.946580</td>\n",
              "      <td>0.212034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6433 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5c8ce96-5018-415a-b8aa-cedfd1e07d14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5c8ce96-5018-415a-b8aa-cedfd1e07d14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5c8ce96-5018-415a-b8aa-cedfd1e07d14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an example to illustrate its application.\n",
        "\n",
        "Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform a high-dimensional dataset into a lower-dimensional space. It achieves this by identifying the principal components, which are orthogonal directions that capture the maximum variance in the data. These principal components represent new uncorrelated variables that can be used to represent the original dataset with reduced dimensions.\n",
        "\n",
        "PCA works by linearly transforming the data onto a new coordinate system defined by the principal components. The first principal component corresponds to the direction of maximum variance in the data, and each subsequent component captures as much remaining variance as possible while being orthogonal (uncorrelated) to the previous components. This allows PCA to capture the most important patterns and structures in the data.\n",
        "\n",
        "Here's an example to illustrate the application of PCA:\n",
        "\n",
        "Suppose we have a dataset with three numerical features: \"Height,\" \"Weight,\" and \"Age.\" Each data point represents an individual.\n",
        "\n",
        "Original dataset:\n",
        "\n",
        "|Height (cm) | Weight (kg) | Age (years) |\n",
        "|:-----------|:------------|:------------|\n",
        "| 170\t       | 60\t         | 30          |\n",
        "| 160\t       | 55          | 25          |\n",
        "| 180        | 70\t         | 35          |\n",
        "| 165        | 63          | 28          |\n",
        "| 175        | 68          | 32          |\n",
        "\n",
        "To apply PCA for dimensionality reduction, we first standardize the data by subtracting the mean and scaling to unit variance. This step ensures that all features contribute equally to the analysis.\n",
        "\n",
        "Next, we compute the covariance matrix or the correlation matrix of the standardized data. The covariance matrix represents the relationships between the features and their variances.\n",
        "\n",
        "From the covariance matrix, we calculate the eigenvectors and eigenvalues. The eigenvectors represent the principal components, and the eigenvalues indicate the amount of variance explained by each component.\n",
        "\n",
        "Suppose the eigenvectors and eigenvalues are as follows:\n",
        "\n",
        "Eigenvectors:\n",
        "\n",
        "|PC1\t|PC2\t|PC3|\n",
        "|-----|-----|----|\n",
        "|0.58\t|0.69\t|0.44|\n",
        "|0.67\t|-0.33\t|-0.66|\n",
        "|-0.47|\t0.67\t|-0.56|\n",
        "\n",
        "Eigenvalues: [1.92, 0.64, 0.04]\n",
        "\n",
        "The eigenvectors are sorted based on their corresponding eigenvalues in descending order. This indicates the amount of variance explained by each principal component.\n",
        "\n",
        "Now, we can choose the desired number of principal components to retain. For instance, if we want to reduce the dimensionality to two, we select the top two eigenvectors (PC1 and PC2).\n",
        "\n",
        "We project the original data onto the selected principal components to obtain the new lower-dimensional representation. This can be done by multiplying the standardized data by the selected eigenvectors.\n",
        "\n",
        "Projected dataset (using PC1 and PC2):\n",
        "\n",
        "|PC1|\tPC2|\n",
        "|---|----|\n",
        "|-0.36|\t-1.32|\n",
        "|-0.62|\t1.47|\n",
        "|1.78\t|-0.18|\n",
        "|-0.41|\t-0.71|\n",
        "|-0.38|\t0.74|\n",
        "\n",
        "The projected dataset represents the original data in a reduced two-dimensional space, where each data point is now represented by its corresponding values along the principal components.\n",
        "\n",
        "PCA allows us to reduce the dimensionality of the dataset while preserving as much information (variance) as possible. The reduced-dimensional representation can be useful for visualization, exploration, and subsequent analysis tasks such as clustering or classification."
      ],
      "metadata": {
        "id": "SsCeCrYbulk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
        "\n",
        "PCA can be used for feature extraction, which involves transforming the original features into a new set of features that are more informative or representative of the underlying patterns in the data. In this context, PCA identifies the most important features or combinations of features, known as principal components, and represents the data using these components.\n",
        "\n",
        "Feature extraction using PCA involves the following steps:\n",
        "\n",
        "Standardize the data: Start by standardizing the dataset to have zero mean and unit variance. This step ensures that all features contribute equally to the PCA analysis.\n",
        "\n",
        "Compute the covariance matrix or correlation matrix: Calculate the covariance matrix (or correlation matrix) of the standardized data. The covariance matrix represents the relationships between the features and their variances.\n",
        "\n",
        "Compute eigenvectors and eigenvalues: Determine the eigenvectors and eigenvalues of the covariance matrix. The eigenvectors represent the principal components, while the eigenvalues indicate the amount of variance explained by each component.\n",
        "\n",
        "Select principal components: Choose the desired number of principal components to retain based on the eigenvalues. Retaining a subset of the principal components allows for dimensionality reduction and feature extraction.\n",
        "\n",
        "Project the data onto the selected principal components: Multiply the standardized data by the selected eigenvectors (principal components) to obtain the new feature representations."
      ],
      "metadata": {
        "id": "7sReBsuOyYSJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
        "\n",
        "To preprocess the data for building a recommendation system for a food delivery service, you can use Min-Max scaling to ensure that the features are on a similar scale. Here's how you can apply Min-Max scaling to the dataset:\n",
        "\n",
        "1. Identify the features: Review the dataset and identify the relevant features that you want to include in the recommendation system. In this case, the features would be price, rating, and delivery time.\n",
        "\n",
        "2. Find the minimum and maximum values: Calculate the minimum and maximum values for each feature. For example, determine the minimum and maximum prices, ratings, and delivery times in the dataset.\n",
        "\n",
        "3. Apply Min-Max scaling formula: Use the Min-Max scaling formula to scale the values of each feature. The formula is:\n",
        "\n",
        "**X_scaled = (X - X_min) / (X_max - X_min)**\n",
        "\n",
        "4. Scale the values: Apply the Min-Max scaling formula to each value of the features separately. For example, for price, you would subtract the minimum price and divide by the range (maximum price minus minimum price). Repeat this process for rating and delivery time as well.\n",
        "\n",
        "5. Obtain the scaled dataset: After scaling all the values, you will have a new dataset where each feature is transformed to a range between 0 and 1. This ensures that all features are on a similar scale and eliminates the influence of their original magnitudes.\n",
        "\n",
        "6. By using Min-Max scaling, the recommendation system can effectively handle features with different value ranges. This preprocessing step ensures that no single feature dominates the recommendation process based solely on its larger or smaller values. Instead, all features are given equal importance in determining the recommendations."
      ],
      "metadata": {
        "id": "9v8ZHgGkzAua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
        "\n",
        "To reduce the dimensionality of the dataset in a project focused on predicting stock prices, you can use PCA (Principal Component Analysis) as a dimensionality reduction technique. Here's how you can use PCA in this scenario:\n",
        "\n",
        "1. Identify the relevant features: Review the dataset and identify the features that are relevant for predicting stock prices. These features may include company financial data (e.g., revenue, earnings, debt) and market trends (e.g., interest rates, market indices).\n",
        "\n",
        "2. Standardize the data: Before applying PCA, it's important to standardize the features to have zero mean and unit variance. Standardization ensures that all features contribute equally to the PCA analysis, as the algorithm is sensitive to the relative scales of the features.\n",
        "\n",
        "3. Apply PCA: Once the data is standardized, apply PCA to the dataset. PCA will identify the principal components, which are new uncorrelated variables that capture the maximum variance in the data.\n",
        "\n",
        "4. Determine the number of principal components: Decide on the number of principal components to retain. This decision can be based on the cumulative explained variance or domain knowledge. Retaining fewer components will result in dimensionality reduction while still preserving the most important patterns in the data.\n",
        "\n",
        "5. Project the data onto the selected principal components: Transform the dataset by projecting the original features onto the selected principal components. This step will create a new dataset with reduced dimensions, where each observation is represented by the values along the principal components.\n",
        "\n",
        "6. Use the reduced dataset for modeling: The reduced-dimensional dataset obtained from PCA can be used as input for modeling algorithms to predict stock prices. The reduced dimensions may help in reducing noise, focusing on the most relevant information, and improving model performance.\n",
        "\n",
        "Using PCA for dimensionality reduction in the context of predicting stock prices can be beneficial as it reduces the computational complexity and helps to handle multicollinearity among the features. By capturing the most important patterns in the data, PCA allows you to focus on the most informative components while discarding less relevant ones. However, it's important to note that the interpretability of the reduced features may be reduced compared to the original features."
      ],
      "metadata": {
        "id": "eyeJf9vkzo2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
        "\n",
        "To perform Min-Max scaling on the given dataset, which is [1, 5, 10, 15, 20], and transform the values to a range of -1 to 1, follow these steps:\n",
        "\n",
        "Find the minimum and maximum values of the dataset:\n",
        "\n",
        "Minimum value (X_min): 1\n",
        "Maximum value (X_max): 20\n",
        "Apply the Min-Max scaling formula:\n",
        "\n",
        "`X_scaled = (X - X_min) / (X_max - X_min)`\n",
        "\n",
        "Scale each value in the dataset using the formula:\n",
        "\n",
        "For the value 1: X_scaled = (`1 - 1) / (20 - 1) = 0 / 19 = 0`\n",
        "\n",
        "For the value 5: X_scaled = `(5 - 1) / (20 - 1) = 4 / 19 ≈ 0.211`\n",
        "\n",
        "For the value 10: X_scaled = `(10 - 1) / (20 - 1) = 9 / 19 ≈ 0.474`\n",
        "\n",
        "For the value 15: X_scaled = `(15 - 1) / (20 - 1) = 14 / 19 ≈ 0.737`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For the value 20: X_scaled = (20 - 1) / (20 - 1) = 19 / 19 = 1\n",
        "\n",
        "Obtain the scaled dataset:\n",
        "\n",
        "The scaled dataset using Min-Max scaling and transforming the values to a range of -1 to 1 is:\n",
        "[0, 0.211, 0.474, 0.737, 1]\n",
        "\n",
        "The original values in the dataset [1, 5, 10, 15, 20] have been transformed to a new range between -1 and 1 using Min-Max scaling. This scaling technique ensures that all values are proportionally scaled based on the range of the original data."
      ],
      "metadata": {
        "id": "_83WVK3Oz81S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
        "\n",
        "To perform feature extraction using PCA on the given dataset with features [height, weight, age, gender, blood pressure], follow these steps to determine the number of principal components to retain:\n",
        "\n",
        "1. Prepare the dataset: Ensure the dataset is properly preprocessed, which may involve handling missing values, encoding categorical variables (such as gender), and scaling the numerical features.\n",
        "\n",
        "2. Standardize the data: Standardize the numerical features (height, weight, age, and blood pressure) to have zero mean and unit variance. This step ensures that all features contribute equally to the PCA analysis.\n",
        "\n",
        "3. Apply PCA: Perform PCA on the standardized dataset. This will yield the principal components, eigenvectors, and eigenvalues.\n",
        "\n",
        "4. Analyze the explained variance: Examine the eigenvalues or the explained variance ratio associated with each principal component. The explained variance ratio indicates the proportion of variance in the data that is explained by each principal component. The cumulative explained variance can help determine the number of principal components to retain.\n",
        "\n",
        "5. Determine the number of principal components: Decide on the number of principal components to retain based on the cumulative explained variance. Retaining a sufficient number of principal components is crucial to capture a significant portion of the variance in the data while reducing dimensionality.\n",
        "\n",
        "The specific number of principal components to retain can vary depending on the dataset and the desired trade-off between dimensionality reduction and preserving information. Common approaches include:\n",
        "\n",
        "* Retaining a fixed number of principal components: You may choose to retain a specific number of principal components based on prior knowledge or the desired level of dimensionality reduction. For example, retaining the top two or three principal components.\n",
        "\n",
        "* Retaining principal components with a minimum explained variance threshold: You can set a minimum threshold for the cumulative explained variance (e.g., 90% or 95%) and retain principal components until that threshold is reached.\n",
        "\n",
        "* Visual analysis: Plotting the scree plot, which shows the eigenvalues or explained variance ratio, can provide insights into the \"elbow point\" where the eigenvalues start to level off. This point may indicate a suitable number of principal components to retain.\n",
        "\n",
        "It's challenging to determine the exact number of principal components to retain without knowing the specific dataset and its characteristics. It is recommended to experiment with different options, such as the explained variance ratio and visual analysis, to find an appropriate balance between dimensionality reduction and information preservation."
      ],
      "metadata": {
        "id": "KDSb6y9c0whe"
      }
    }
  ]
}